{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas\n",
    "from gensim import corpora, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 8000\n",
    "NUM_TOPIC = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_ful = pandas.read_csv('./train.csv')\n",
    "docs = docs_ful['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = docs.astype(str).apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary= gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77581"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=2, no_above=0.7, keep_n=DICT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=NUM_TOPIC, id2word=dictionary, passes=2, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719\n"
     ]
    }
   ],
   "source": [
    "# After lda_model\n",
    "# Test\n",
    "docs_ful_val = pandas.read_csv('./test.csv')\n",
    "docs_val = docs_ful_val['content']\n",
    "\n",
    "bow_corpus_val = [dictionary.doc2bow(doc) for doc in docs_val.astype(str).apply(lambda x: x.split())]\n",
    "corpus_tfidf_val = tfidf[bow_corpus_val]\n",
    "\n",
    "data_after_lda = []\n",
    "for cor in corpus_tfidf_val:\n",
    "    temp = [0] * NUM_TOPIC\n",
    "    for index_topic, val in lda_model_tfidf[cor]:\n",
    "        temp[index_topic] = val\n",
    "    data_after_lda.append(temp)\n",
    "data = pandas.DataFrame(data={'data': data_after_lda, 'label': docs_ful_val['label']})\n",
    "print(len(data_after_lda))\n",
    "os.mkdir('./data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC))\n",
    "data.to_csv('./data/v' + str(DICT_SIZE)+ '_tp' + str(NUM_TOPIC) + '/after_lda_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2255\n"
     ]
    }
   ],
   "source": [
    "# After lda_model\n",
    "# Val\n",
    "docs_ful_val = pandas.read_csv('./val.csv')\n",
    "docs_val = docs_ful_val['content']\n",
    "\n",
    "bow_corpus_val = [dictionary.doc2bow(doc) for doc in docs_val.astype(str).apply(lambda x: x.split())]\n",
    "corpus_tfidf_val = tfidf[bow_corpus_val]\n",
    "\n",
    "data_after_lda = []\n",
    "for cor in corpus_tfidf_val:\n",
    "    temp = [0] * NUM_TOPIC\n",
    "    for index_topic, val in lda_model_tfidf[cor]:\n",
    "        temp[index_topic] = val\n",
    "    data_after_lda.append(temp)\n",
    "data = pandas.DataFrame(data={'data': data_after_lda, 'label': docs_ful_val['label']})\n",
    "print(len(data_after_lda))\n",
    "data.to_csv('./data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) + '/after_lda_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7893\n"
     ]
    }
   ],
   "source": [
    "# After lda_model\n",
    "# Train\n",
    "data_after_lda = []\n",
    "for cor in corpus_tfidf:\n",
    "    temp = [0] * NUM_TOPIC\n",
    "    for index_topic, val in lda_model_tfidf[cor]:\n",
    "        temp[index_topic] = val\n",
    "    data_after_lda.append(temp)\n",
    "data = pandas.DataFrame(data={'data': data_after_lda, 'label': docs_ful['label']})\n",
    "print(len(data_after_lda))\n",
    "data.to_csv('./data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) + '/after_lda_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data\n",
    "def convert(s):\n",
    "    if s == 'giao_duc':\n",
    "        return 0\n",
    "    elif s == 'the_gioi':\n",
    "        return 1\n",
    "    elif s == 'phap_luat':\n",
    "        return 2\n",
    "    elif s == 'giai_tri':\n",
    "        return 3\n",
    "    elif s == 'kinh_doanh':\n",
    "        return 4\n",
    "    elif s == 'van_hoa':\n",
    "        return 5\n",
    "    elif s == 'khoa_hoc':\n",
    "        return 6\n",
    "    elif s == 'the_thao':\n",
    "        return 7\n",
    "    elif s == 'suc_khoe':\n",
    "        return 8\n",
    "    elif s == 'xe':\n",
    "        return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pandas.read_csv('./data/v' + str(DICT_SIZE)+ '_tp' + str(NUM_TOPIC) + '/after_lda_train.csv')\n",
    "temp['label'] = [convert(s) for s in temp['label']]\n",
    "temp = pandas.DataFrame(data={'data': temp['data'], 'label':temp['label']})\n",
    "os.mkdir('pj/data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC))\n",
    "temp.to_csv('pj/data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) + '/after_lda_train.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pandas.read_csv('./data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) + '/after_lda_test.csv')\n",
    "temp['label'] = [convert(s) for s in temp['label']]\n",
    "temp = pandas.DataFrame(data={'data': temp['data'], 'label':temp['label']})\n",
    "temp.to_csv('pj/data/v' + str(DICT_SIZE)+ '_tp' + str(NUM_TOPIC) + '/after_lda_test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pandas.read_csv('./data/v' + str(DICT_SIZE)+ '_tp' + str(NUM_TOPIC) + '/after_lda_val.csv')\n",
    "temp['label'] = [convert(s) for s in temp['label']]\n",
    "temp = pandas.DataFrame(data={'data': temp['data'], 'label':temp['label']})\n",
    "temp.to_csv('pj/data/v' + str(DICT_SIZE) + '_tp' + str(NUM_TOPIC) + '/after_lda_val.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import ast\n",
    "\n",
    "data = ['test', 'val', 'train']\n",
    "\n",
    "for type_set in data:\n",
    "    with open('pj/data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) + '/after_lda_{}.csv'.format(type_set), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        X = []\n",
    "        Y = []\n",
    "        for line in lines:\n",
    "            x = ast.literal_eval(line[1:-4])\n",
    "            y = line[-2]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "        X = np.array(X).astype(np.float64)\n",
    "        Y = np.array(Y).reshape(-1,1).astype(np.float64)\n",
    "        np.save('pj/data/v' + str(DICT_SIZE) + '_tp' + str(NUM_TOPIC) + '/{}_{}.npy'.format(type_set, str(NUM_TOPIC)), np.hstack([X, Y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val 0.5161862527716187\n",
      "test 0.4603616133518776\n"
     ]
    }
   ],
   "source": [
    "# Run Svm\n",
    "import numpy as np \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "train_set = np.load('pj/data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) +'/train_' + str(NUM_TOPIC)+'.npy')\n",
    "val_set = np.load('pj/data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) +'/val_'+str(NUM_TOPIC)+'.npy')\n",
    "test_set = np.load('pj/data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) +'/test_'+str(NUM_TOPIC)+'.npy')\n",
    "\n",
    "X_train = train_set[:, :-1]\n",
    "Y_train = train_set[:, -1]\n",
    "X_val = val_set[:, :-1]\n",
    "Y_val = val_set[:, -1]\n",
    "X_test = test_set[:, :-1]\n",
    "Y_test = test_set[:, -1]\n",
    "\n",
    "clf = SVC(kernel='rbf', degree=3, gamma='auto')\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "score = clf.score(X_val, Y_val)\n",
    "print('val', score)\n",
    "score1 = clf.score(X_test, Y_test)\n",
    "print('test', score1)\n",
    "\n",
    "with open('pj/data/v' + str(DICT_SIZE) +'_tp' + str(NUM_TOPIC) +'/result.txt', 'w') as f:\n",
    "    f.write('val ' + str(score)+'\\n')\n",
    "    f.write('test ' + str(score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
